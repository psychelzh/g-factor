{
  "hash": "eac5ea0cb20840d9a2c004850661d901",
  "result": {
    "markdown": "---\ntitle: Benchmark Neural Predictability of G-factor\nauthor: Liang Zhang\ndate: 2023-05-10\ndraft: false\nformat:\n  revealjs:\n    code-fold: false\nexecute:\n  warning: false\n  message: false\nbibliography: references.bib\n---\n\n\n\n\n# FMRI Sample Description\n\n\n745 participants (Mean age = 20.9, SD = 2.2, range: [17, 29]; Sex: 63.0% females, 37.0% males, 0.0% other)\n\n\n# Compare CPM among different modalities\n\n## Configurations {.smaller}\n\nParameters are as follows (mainly inspired by @greene2018):\n\n-   FMRI data pre-processing: `with` or `without` global signal regression (GSR)\n-   Node parcellation: Power's *264* nodes (`Power264`) or Shen's *268* nodes (`nn268`)\n-   Modality:\n    -   `task`: N-back task\n    -   `rest`: resting-state\n    -   `combined`: combines N-back and rest-stating by appending these two data\n-   Edge selection threshold method: correlation p.value based (`alpha`) or network sparsity based (`sparsity`)\n\n\n## Parcel Shen268 with GSR\n\n::: {.cell}\n::: {.cell-output-display}\n![CPM prediction among different modality.](bench_cpm_files/figure-revealjs/fig-modality-nn268-with-1.png){#fig-modality-nn268-with width=1152}\n:::\n:::\n\n## Parcel Shen268 without GSR\n\n::: {.cell}\n::: {.cell-output-display}\n![CPM prediction among different modality.](bench_cpm_files/figure-revealjs/fig-modality-nn268-without-1.png){#fig-modality-nn268-without width=1152}\n:::\n:::\n\n## Parcel Power264 with GSR\n\n::: {.cell}\n::: {.cell-output-display}\n![CPM prediction among different modality.](bench_cpm_files/figure-revealjs/fig-modality-Power264-with-1.png){#fig-modality-Power264-with width=1152}\n:::\n:::\n\n## Parcel Power264 without GSR\n\n::: {.cell}\n::: {.cell-output-display}\n![CPM prediction among different modality.](bench_cpm_files/figure-revealjs/fig-modality-Power264-without-1.png){#fig-modality-Power264-without width=1152}\n:::\n:::\n\n\n# Compare between gender/sex\n\n\n## Parcel Shen268 with GSR\n\n::: {.cell}\n::: {.cell-output-display}\n![CPM prediction between different sex.](bench_cpm_files/figure-revealjs/fig-sex-nn268-with-1.png){#fig-sex-nn268-with width=1152}\n:::\n:::\n\n## Parcel Shen268 without GSR\n\n::: {.cell}\n::: {.cell-output-display}\n![CPM prediction between different sex.](bench_cpm_files/figure-revealjs/fig-sex-nn268-without-1.png){#fig-sex-nn268-without width=1152}\n:::\n:::\n\n## Parcel Power264 with GSR\n\n::: {.cell}\n::: {.cell-output-display}\n![CPM prediction between different sex.](bench_cpm_files/figure-revealjs/fig-sex-Power264-with-1.png){#fig-sex-Power264-with width=1152}\n:::\n:::\n\n## Parcel Power264 without GSR\n\n::: {.cell}\n::: {.cell-output-display}\n![CPM prediction between different sex.](bench_cpm_files/figure-revealjs/fig-sex-Power264-without-1.png){#fig-sex-Power264-without width=1152}\n:::\n:::\n\n\n# Model g with the Highest Loading Tasks\n\nThe following is to test whether the correlation between the estimated g-factor scores and the brain functional connectivity can be improved by eliminating certain observed variables, e.g., those with the least factor loading.\n\n> Note: all following calculations are based on **Power's 264-node parcellation** and **p-value based** threshold method, which appears to have a better prediction accuracy.\n\n## Trends by Number of Kept tasks  {.smaller}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![The correlation between g factor scores and brain functional connectivity reaches plateau after 6 variables of largest factor loading were included, whereas that of RAPM scores reaches plateau after 13 variables. This might indicate that more variables might not necesssarily be beneficial to the measure of g-factor estimation, esp. when adding low g loading tasks.](bench_cpm_files/figure-revealjs/fig-tasksel-neural-correlation-1.png){#fig-tasksel-neural-correlation width=768}\n:::\n:::\n\n\n## Single Task Benchmark\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Correlation with brain FC for single tasks. The tasks are ordered by the factor loading in one g factor model.](bench_cpm_files/figure-revealjs/fig-single-tasks-1.png){#fig-single-tasks width=768}\n:::\n:::\n\n\n# References\n",
    "supporting": [
      "bench_cpm_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}