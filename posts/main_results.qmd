---
title: The neural substrates of general cognitive ability based on multiple cognitive tasks
author: Liang Zhang
date: 2023-06-30
format:
  revealjs:
    code-fold: false
execute:
  warning: false
  message: false
bibliography: references.bib
csl: modified-chicago.csl
---

```{r}
#| label: setup

conflicted::conflicts_prefer(dplyr::filter())
devtools::load_all()
knitr::opts_chunk$set(dev = "ragg_png")
```

# Issues on Intelligence

## Definition {.smaller}

::: notes
The definition was never and probably won't be consistent.
:::

-   Binet: "judgment, otherwise called good sense, practical sense, initiative, the faculty of adapting one's self to circumstances"
-   Gardner: "the ability to solve problems, or to create products, that are valued within one or more cultural settings"
-   "Ability to understand complex ideas, to adapt effectively to the environment, to learn from experience, to engage in various forms of reasoning, to overcome obstacles by taking thought." [@neisser1996]
-   "\[A\] very general mental capability that, among other things, involves the ability to reason, plan, solve problems, think abstractly, comprehend complex ideas, learn quickly and learn from experience. It is not merely book learning, a narrow academic skill, or test-taking smarts. Rather, it reflects a broader and deeper capability for comprehending our surroundings catching on, making sense of things, or figuring out what to do." [@gottfredson1997]
-   "A general cognitive ability related to solving problems efficiently and effectively." [@thecamb2021]

## Intelligence and g

::: incremental
-   General intelligence (i.e., g-factor) was first proposed by Spearman [-@spearman1904] to account for the "positive manifold" phenomenon of cognitive tests.

-   Given the term "intelligence" is hard to define and easily leads to confusion, many researchers (see Jensen [-@jensen1998]) focused on the g (i.e., general intelligence) [@haier2017; @thecamb2021].

-   Current cognitive scientists also defined intelligence as general cognitive ability [@thecamb2021], which can be derived by multiple cognitive tasks
:::

## Diagram of g and its Relatives

![Conceptual relationships among mental abilities, intelligence, IQ, and the g-factor [@theinte2013]](images/mental-ability-diagram.png){fig-align="center"}

::: notes
Savants are those with very high specific abilities but no general intelligence (e.g., Kim Peek, AI of current days).
:::

## Measure of g

::: incremental
-   Two major influences: **sampling of participants** and **sampling of cognitive tasks**

-   Here we focus on the issue of tasks sampling

    -   Factor analysis method

    -   Task sampling representativeness
:::

## Factor Modeling

::: incremental
-   There are several different factor analysis modeling method:

    -   Spearman Model

    -   Bifactor Model

    -   Orthogonalized Hierarchical Model

-   Jensen [-@jensen1998] found that the g-factor scores is extremely stable among different methods, with correlation coefficients ranging from 0.991 to 1.000. Here we just focus the classical Spearman model for its simplicity.
:::

## Invariance of g

::: columns
::: {.column width="50%"}
![Test batteries used](images/johnson2004.png){fig-align="center"}
:::

::: {.column width="50%"}
![Consistency between g estimated from three batteries [@johnson2004]](images/one-g-three-battery.png){fig-align="center"}
:::
:::

## Invariance of g

::: columns
::: {.column width="50%"}
![Test Batteries Used](images/johnson2008.png){fig-align="center"}
:::

::: {.column width="50%"}
![Consistency between g estimated from five batteries [@johnson2008]](images/one-g-five-battery.png){fig-align="center"}
:::
:::

## Number of tasks used in international projects {.smaller}

| Project                   | Number of Cognitive Tasks | Ref                 |
|---------------------|---------------------|------------------------------|
| UK Biobank (2004)         | 4                         | @cox2019            |
| HCP (2009)                | 12                        | @dubois2018         |
| Aging Brain Cohort (2021) | 5 (part of NIH toolbox)   | @newman-norlund2021 |
| ABCD Study (2015)         | 10 (7 from NIH toolbox)   | @thompson2019       |

## Research Questions

::: incremental
-   How the number of tasks affect the measure of g?
    -   More reliable and more valid?
-   Can neural predictability be improved by including more tasks?
    -   More predictable and shows more reliable predicting networks?
-   What are the exact neural substrate of g based on multiple cognitive tasks?
:::

# Our Dataset

## Cognitive Tasks {.smaller}

-   19 Tasks (20 task indices) included
    -   **Working Memory** (*5*): Letter 3-back, Spatial 2-back, Keep Track, Operation Complex Span, Symmetry Complex Span
    -   **Response Inhibition** (*3*): Anti-Saccade (2 indices), Stop-Signal, Stroop
    -   **Shifting** (*3*): Size-Life Judgment, Color-Shape Judgment, Number-Letter Judgment
    -   **Learning and Memory** (*3*): Face Name Association, Symbol Memory, Pattern Separation
    -   **Attention and Speed** (*5*): Continuous Performance Test, Filtering Task, Line Orientation, Simple Reaction Time, Choice Reaction Time

## Sample Size

```{r}
targets::tar_load(
  c(subjs_info_clean, indices_wider_clean, indices_clean),
  store = store_preproc_behav
)
targets::tar_load(subjs_combined, store = store_bench_cpm)
descr_behav <- subjs_info_clean |>
  semi_join(indices_wider_clean, by = "sub_id") |>
  select(sub_id, age, sex) |>
  report::report_participants()
descr_fmri <- subjs_info_clean |>
  filter(sub_id %in% subjs_combined) |>
  select(sub_id, age, sex) |>
  report::report_participants()
```

-   Behavior sample: `r descr_behav`

-   FMRI sample: `r descr_fmri`

<!-- ## Missing Pattern -->

```{r}
#| label: fig-miss-pat
#| fig-width: 8
#| fig-height: 6
#| eval: false
#| fig-cap: >
#|   **Behavior Data Missing Pattern**.

indices_wider_clean |>
  select(-sub_id) |>
  naniar::vis_miss(sort_miss = TRUE, cluster = TRUE) +
  theme(axis.text.x = element_text(angle = 90))
```

<!-- ## Data Distribution -->

```{r}
#| label: fig-dist-pat
#| fig-width: 8
#| fig-height: 8
#| eval: false
#| fig-cap: >
#|   **Behavior Performance Distribution**.

indices_clean |> 
  filter(sub_id < 17000) |>
  filter(!performance::check_outliers(score, method = "iqr"), .by = c(disp_name, index)) |> 
  semi_join(indices_wider_clean, by = "sub_id") |> 
  ggplot(aes(score)) +
  geom_histogram(bins = 30, na.rm = TRUE) +
  facet_wrap(~ disp_name + index, scales = "free") +
  theme_bw()
```

## Explained Variance

```{r}
#| label: fig-var-exp
#| fig-width: 8
#| fig-height: 6
#| fig-cap: >
#|   **Variance Explained by the g Factor.** The horizontal line gives the variance explained
#|   by the g factor estimated from all the tasks.

targets::tar_load(var_exp, store = store_g_invariance)
targets::tar_load(var_exp_full, store = store_preproc_behav)
var_exp |>
  ggplot(aes(num_vars, prop)) +
  ggdist::stat_slabinterval() +
  ggdist::stat_dots(side = "left") +
  geomtextpath::geom_texthline(
    yintercept = var_exp_full,
    hjust = 1,
    color = "blue4",
    label = "All Tasks"
  ) +
  scale_x_continuous(breaks = scales::breaks_width(2)) +
  ggpubr::theme_pubclean() +
  labs(x = "Number of Tasks", y = "Variance Explained")
```

## Correlation with RAPM

```{r}
#| label: fig-g-raven
#| fig-width: 8
#| fig-height: 6
#| fig-cap: >
#|   **Correlation with Raven's Advanced Progressive Matrices (RAPM) scores**. The
#|   horizontal line is the correlation between gF score estimated from all task
#|   indices and RAPM.

targets::tar_load(scores_g, store = store_g_invariance)
targets::tar_load(
  c(scores_g_full, indices_rapm),
  store = store_preproc_behav
)
cor_rapm_full <- scores_g_full |>
  inner_join(indices_rapm, by = "sub_id") |>
  summarise(cor = cor(g, RAPM, use = "pairwise"))
cor_rapm_sampled <- scores_g |>
  unnest(scores) |>
  inner_join(indices_rapm, by = "sub_id") |>
  summarise(
    cor = cor(g, RAPM, use = "pairwise"),
    .by = c(num_vars, id_pairs, idx_rsmp)
  )
cor_rapm_sampled |>
  ggplot(aes(num_vars, cor)) +
  ggdist::stat_slabinterval() +
  ggdist::stat_dots(side = "left") +
  geomtextpath::geom_texthline(
    yintercept = cor_rapm_full$cor,
    hjust = 1,
    color = "blue4",
    label = "All Tasks"
  ) +
  ggpubr::theme_pubclean() +
  labs(x = "Number of Tasks", y = "Correlation Coefficient")
```

<!-- ## High RAPM Correlation tasks -->

```{r}
#| label: fig-rapm-cor-tasks
#| fig-width: 15
#| fig-height: 5
#| fig-cap: >
#|   **Top RAPM correlated tasks.** The tasks for each top 10 samples are displayed.
#| eval: false

targets::tar_load(data_names, store = store_g_invariance)
tasks_high_cor_rapm <- cor_rapm_sampled |>
  slice_max(cor, n = 10, by = num_vars) |>
  inner_join(
    data_names,
    by = c("num_vars", "id_pairs", "idx_rsmp")
  ) |>
  unnest(tasks)
tasks_high_cor_rapm |>
  group_by(num_vars, tasks) |>
  summarise(n = n(), .groups = "drop_last") |>
  mutate(prop = n / sum(n)) |>
  ungroup() |>
  ggplot(aes(label = tasks, size = prop)) +
  geom_text_wordcloud_area(seed = 1) +
  scale_size_area(max_size = 8) +
  facet_grid(cols = vars(num_vars))
```

## Correlation between estimated g in Pairwise Sampling {.smaller}

```{r}
#| label: fig-g-pair-cor
#| fig-width: 8
#| fig-height: 6
#| fig-cap: >
#|   **The correlation between g scores estimated from each pair of sampling.**
#|   For each sampling, a pair of equal-number tasks are drawed without
#|   replacement. So the maximal number of tasks will be 10, and this figure
#|   shows that the correlations between the paired g scores increase as the
#|   number of tasks increase.

scores_g |>
  group_by(num_vars, idx_rsmp) |>
  filter(n() == 2) |>
  summarise(
    estimate = cor(scores[[1]]$g, scores[[2]]$g, use = "pairwise"),
    .groups = "drop"
  ) |>
  ggplot(aes(num_vars, estimate)) +
  ggdist::stat_slabinterval() +
  ggdist::stat_dots(side = "left") +
  scale_x_continuous(breaks = scales::breaks_width(2)) +
  ggpubr::theme_pubclean() +
  labs(x = "Number of Tasks", y = "Correlation Between Pairs")
```

::: notes
Seemingly the correlation reaches a plateau? But I am doubting here.
:::

# Neural Predictability

## CPM hyperparamters checking

```{r}
#| label: fig-bench-cpm-hypers
#| fig-width: 8
#| fig-height: 6
#| fig-cap: >
#|   Compare different CPM hyper-parameters. We chose a threshhold method based
#|   on alpha level of correlation and a threshhold level at 0.01. 

targets::tar_load(
  cpm_pred_reg_nosite, 
  store = store_bench_cpm
)

pred_hypers <- cpm_pred_reg_nosite |> 
  filter(
    idx == "rapm",
    filt == "bandpass", 
    gsr == "with"
  ) |> 
  mutate(
    cond = factor(cond, names(conds)),
    parcel = factor(parcel, names(parcels)),
    gsr = factor(gsr, names(gsrs))
  )
pred_hypers |> 
  ggplot(aes(thresh_method, all, fill = factor(thresh_level))) +
  ggdist::stat_dots(position = position_dodge(width = 0.5), side = "left") +
  ggdist::stat_slabinterval(position = position_dodge(width = 0.5)) +
  ggrepel::geom_label_repel(
    aes(label = thresh_level), 
    data = pred_hypers |> 
      slice_max(
        order_by = all,
        by = c(cond, parcel, thresh_method, thresh_level)
      ),
    position = position_dodge(width = 0.5),
    show.legend = FALSE
  ) +
  rlang::exec(scale_x_discrete, !!!scale_thresh_methods) +
  scale_y_continuous(name = "Prediction (combined network)") +
  scale_fill_brewer(type = "seq", name = "Level", guide = "none") +
  facet_grid(
    cols = vars(cond),
    rows = vars(parcel),
    labeller = labeller(
      cond = conds, 
      parcel = parcels
    )
  ) +
  ggpubr::theme_pubclean()
```

## Find the best task condition to predict intelligence {.smaller}

```{r}
#| label: fig-bench-cpm
#| fig-width: 8
#| fig-height: 6
#| fig-cap: >
#|   Using CPM method to predict Raven score by FC from different states, we found
#|   that task-induced (i.e. n-back task) showed best performance, though combing
#|   task and resting states using the first principal component showed comparable
#|   performance. What's more, global signal regression will enhance the performance, 
#|   whereas different parcellation showed comparable performance.

cpm_pred_reg_nosite |> 
  filter(
    idx == "rapm", 
    filt == "bandpass", 
    thresh_method == "alpha", 
    thresh_level == 0.01
  ) |> 
  pivot_longer(
    all_of(names(model_types)),
    names_to = "model_type",
    values_to = "estimate"
  ) |> 
  mutate(
    cond = factor(cond, names(conds)),
    parcel = factor(parcel, names(parcels)),
    model_types = factor(model_type, names(model_types)),
    gsr = factor(gsr, names(gsrs))
  ) |> 
  ggplot(aes(cond, estimate, fill = parcel)) +
  ggdist::stat_dots(position = position_dodge(width = 0.4), side = "left") +
  ggdist::stat_slabinterval(position = position_dodge(width = 0.4)) +
  rlang::exec(scale_x_discrete, !!!scale_conds) +
  scale_y_continuous(name = "Prediction") +
  rlang::exec(scale_fill_brewer, !!!scale_parcels, palette = "Dark2") +
  facet_grid(
    rows = vars(model_type),
    cols = vars(gsr),
    labeller = labeller(
      model_type = model_types,
      gsr = gsrs
    )
  ) +
  ggpubr::theme_pubclean()
```

## Prediction Trending

```{r}
#| label: fig-pred-trend
#| fig-width: 8
#| fig-height: 6
#| fig-cap: >
#|   **Prediction Trending (based on CPM)**.

targets::tar_load(cpm_pred_main_reg_nosite, store = store_cpm_main)
targets::tar_load(cpm_pred_reg_nosite, store = store_g_invariance)
preds_main <- cpm_pred_main_reg_nosite |>
  filter(
    cond == "nbackrun1",
    parcel == "nn268",
    filt == "bandpass",
    gsr == "with", 
    thresh_method == "alpha", 
    thresh_level == 0.01
  ) |>
  summarise(
    estimate = mean(all),
    .by = c(idx, any_of(c(names(config_neural), names(hypers_cpm))))
  )
preds_sampled <- cpm_pred_reg_nosite |>
  filter(gsr == "with", parcel == "Power264") |>
  summarise(
    estimate = mean(all),
    .by = c(
      num_vars, id_pairs, idx_rsmp,
      any_of(c(names(config_neural), names(hypers_cpm)))
    )
  )
preds_sampled |>
  ggplot(aes(num_vars, estimate)) +
  ggdist::stat_slabinterval() +
  ggdist::stat_dots(side = "left") +
  # geom_hline(
  #   aes(color = idx, yintercept = estimate),
  #   preds_main
  # ) +
  geomtextpath::geom_texthline(
    aes(label = meas_behav[idx], yintercept = estimate, color = idx),
    preds_main,
    hjust = 0
  ) +
  rlang::exec(
    scale_color_brewer, !!!scale_meas_behv, 
    guide = "none", palette = "Set1"
  ) +
  ggpubr::theme_pubclean() +
  labs(x = "Number of Tasks", y = "Correlation Coefficient")
```

<!-- ## High Neural Correlation Tasks {.smaller} -->

<!-- TODO: this is not the best method for domain checking -->

```{r}
#| label: fig-neural-pred-tasks
#| fig-width: 10
#| fig-height: 6
#| fig-cap: >
#|   **Top predictability tasks.** The tasks for each top 10 predictability samples are displayed.
#| cache: true
#| eval: false

tasks_high_pred <- preds_sampled |>
  slice_max(cor, n = 10, by = c(num_vars, edge_type)) |>
  inner_join(
    data_names,
    by = c("num_vars", "id_pairs", "idx_rsmp"),
    multiple = "all"
  ) |>
  unnest(tasks)
tasks_high_pred |>
  group_by(num_vars, edge_type, tasks) |>
  summarise(n = n(), .groups = "drop_last") |>
  mutate(prop = n / sum(n)) |>
  ungroup() |>
  ggplot(aes(label = tasks, size = prop)) +
  geom_text_wordcloud_area(seed = 1) +
  scale_size_area(max_size = 8) +
  facet_grid(
    vars(edge_type), vars(num_vars),
    labeller = labeller(
      edge_type = c(
        all = "Combined",
        neg = "Anti-Corr Networks",
        pos = "Pos-Corr Networks"
      )
    )
  )
```

::: notes
-   Reaction times tasks are most predictable from neural data, but we should notice the difference with the high RAPM tasks.
-   Here we will appeal to the definition of g factor. g factor is the ability that is domain-general and cannot be estimated from only several domain-specific tasks.
:::

```{r}
#| label: load-data-dice

targets::tar_load(dice_mask_pairs, store = store_g_invariance)
dice_clean <- dice_mask_pairs |>
  filter(reg_covars == "yes") |> 
  pivot_longer(
    contains("dice"),
    names_to = c("model_type", ".value"),
    names_pattern = "(.+)_(.+)"
  ) |>
  mutate(
    cond = factor(cond, names(conds)),
    model_type = factor(model_type, names(model_types))
  )
```

## Similarity Between Predictive Network of Pairs

```{r}
#| label: fig-dice-value
#| fig-width: 12
#| fig-height: 6
#| fig-cap: >
#|   **Dice coefficient between each pair of predictive network in pairwise
#|   sampling.** The edges are kept when given proportion of resamples selected.
#|   Here only the results from task state are shown.

dice_clean |>
  filter(
    parcel == "nn268",
    thresh_method == "alpha",
    binarize_method == "value",
    binarize_level <= 0.95,
    cond == "nbackrun1"
  ) |>
  ggplot(aes(num_vars, dice)) +
  ggdist::stat_slabinterval() +
  ggdist::stat_dots(side = "left") +
  scale_x_continuous(breaks = scales::breaks_width(3)) +
  ggpubr::theme_pubclean() +
  ggh4x::facet_nested(
    model_type ~ "Minimal Proportion" + binarize_level,
    labeller = labeller(
      model_type = model_types
    )
  ) +
  labs(x = "Number of Tasks", y = "Dice Similarity")
```

## Similarity Between Predictive Network of Pairs

```{r}
#| label: fig-dice-count
#| fig-width: 12
#| fig-height: 6
#| fig-cap: >
#|   **Dice coefficient between each pair of predictive network in pairwise
#|   sampling.** Only the most selected of given number of edges are kept. Here
#|   only the results from task state are shown.

dice_clean |>
  filter(
    parcel == "Power264",
    thresh_method == "alpha",
    binarize_method == "count",
    binarize_level %in% seq(200, 1000, 200),
    cond == "nbackrun1"
  ) |>
  ggplot(aes(num_vars, dice)) +
  ggdist::stat_slabinterval() +
  ggdist::stat_dots(side = "left") +
  scale_x_continuous(breaks = scales::breaks_width(3)) +
  ggpubr::theme_pubclean() +
  ggh4x::facet_nested(
    model_type ~ "Top N Edges" + binarize_level,
    labeller = labeller(
      model_type = model_types
    )
  ) +
  labs(x = "Number of Tasks", y = "Dice Similarity")
```

<!-- ## A Caveat -->

```{r}
#| label: fig-pair-flaw
#| fig-width: 12
#| fig-height: 6
#| eval: false
#| fig-cap: >
#|   **Check if pairs are really independent.**

cpm_pred |>
  filter(gsr == "with") |>
  filter(n_distinct(id_pairs) == 2, .by = num_vars) |>
  summarise(
    across(all_of(names(model_types)), mean),
    .by = c(
      num_vars, id_pairs, idx_rsmp,
      any_of(names(config_neural)),
      any_of(names(hypers_cpm))
    )
  ) |>
  pivot_longer(
    all_of(names(model_types)),
    names_to = "model_type",
    values_to = "estimate"
  ) |>
  pivot_wider(
    names_from = id_pairs,
    values_from = estimate
  ) |>
  ggplot(aes(`1`, `2`, color = modal)) +
  geom_point() +
  ggpmisc::stat_correlation(
    ggpmisc::use_label(c("r", "p")),
    small.p = TRUE
  ) +
  facet_grid(
    model_type ~ num_vars,
    labeller = labeller(
      model_type = model_types,
      num_vars = label_both
    )
  ) +
  rlang::exec(scale_color_viridis_d, scale_modalities) +
  labs(x = "First Sample", y = "Second Sample") +
  theme_bw()
```

# Model g with the Highest Loading Tasks

The following is to test whether the correlation between the estimated g-factor scores and the brain functional connectivity can be improved by eliminating certain observed variables, e.g., those with the least factor loading.

## Trends by Number of Kept tasks {.smaller}

```{r}
#| label: fig-tasksel-neural-correlation
#| fig-height: 6
#| fig-width: 8
#| fig-cap: >
#|   The correlation between g factor scores and brain functional connectivity
#|   reaches plateau after 6 variables of largest factor loading were included,
#|   whereas that of RAPM scores reaches plateau after 13 variables. This might
#|   indicate that more variables might not necesssarily be beneficial to
#|   the measure of g-factor estimation, esp. when adding low g loading tasks.

targets::tar_load(cpm_pred_reg_nosite, store = store_task_selection)
targets::tar_load(scores_g, store = store_task_selection)
targets::tar_load(behav_main, store = store_preproc_behav)
behav_cor <- expand_grid(
  rename(scores_g, tasksel = scores),
  rename(behav_main, baseline = scores)
) |>
  mutate(
    map2(
      tasksel, baseline,
      ~ .x |>
        inner_join(.y, by = "sub_id") |>
        summarise(estimate = cor(pick(2), pick(3), use = "pairwise"))
    ) |>
      list_rbind(),
    .keep = "unused"
  )
cpm_pred_reg_nosite |>
  pivot_longer(
    all_of(names(model_types)),
    names_to = "model_type",
    values_to = "estimate"
  ) |>
  mutate(
    cond = factor(cond, names(conds)),
    gsr = factor(gsr, names(gsrs))
  ) |>
  ggplot(aes(max_num_vars - n_rm, estimate)) +
  ggdist::stat_slabinterval() +
  ggdist::stat_dots(aes(color = parcel), side = "left") +
  geom_point(
    aes(max_num_vars - n_rm, estimate, color = idx),
    behav_cor |> filter(idx == "rapm")
  ) +
  # facet_grid(
  #   cols = vars(cond),
  #   rows = vars(gsr),
  #   labeller = labeller(
  #     cond = conds,
  #     gsr = gsrs
  #   )
  # ) +
  scale_x_continuous(
    breaks = scales::breaks_width(3),
    name = "Number of Kept Variables"
  ) +
  scale_color_manual(
    name = "",
    values = c(rapm = "blue4", Power264 = "grey"),
    labels = c(
      rapm = "Correlation with RAPM scores",
      Power264 = "Correlation with FC (by CPM)"
    )
  ) +
  scale_y_continuous(name = "Pearson's Correlation") +
  ggpubr::theme_pubclean()
```

## Single Task Benchmark

```{r}
#| label: fig-single-tasks
#| fig-width: 8
#| fig-height: 6
#| fig-cap: >
#|   Correlation with brain FC for single tasks. The tasks are ordered by the
#|   factor loading in one g factor model.

targets::tar_load(
  c(cpm_pred_single_reg_nosite, data_names_ordered),
  store = store_task_selection
)
bind_rows(
  `Single Task` = cpm_pred_single_reg_nosite,
  `Intelligence` = cpm_pred_main_reg_nosite |> 
      filter(
        parcel == "Power264",
        cond == "nbackrun1",
        filt == "bandpass",
        gsr == "with",
        thresh_method == "alpha", 
        thresh_level == 0.01
      ) |> 
      rename(task = idx),
  .id = "type"
) |> 
  mutate(
    type = factor(type, c("Intelligence", "Single Task")),
    task = factor(
      task, 
      c(names(meas_behav), data_names_ordered),
      c(meas_behav, data_names_ordered)
    )
  ) |>
  mutate(
    cond = factor(cond, names(conds)),
    gsr = factor(gsr, names(gsrs))
  ) |>
  ggplot(aes(fct_reorder(task, desc(all)), all)) +
  ggdist::stat_slabinterval() +
  ggdist::stat_dots(side = "left") +
  facet_grid(
    cols = vars(type), space = "free", scales = "free_x"
  ) +
  ggpubr::theme_pubclean() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1)) +
  labs(x = "Task Name (Descending Loading)", y = "Correlation with FC")
```

# Model-selected Networks Analysis

```{r}
#| label: render-brain-mask
#| results: asis

brain_mask_main <- targets::tar_read(
  brain_mask_main_reg_covars2, 
  store = store_cpm_main
) |> 
  filter(
    parcel == "Power264", filt == "bandpass", gsr == "with",
    thresh_method == "alpha", thresh_level == 0.001,
    cond %in% c("nbackrun1", "rest")
  )
roi_labels <- readRDS(here::here("config/atlas_power.rds")) |>
  prepare_roi_labels()
roi_coords <- as.matrix(select(roi_labels, contains("mni")))
config <- distinct(brain_mask_main, cond)
options(chord.link.val = "relative")
for (row in seq_len(nrow(config))) {
  knitr::knit_expand(
    "template/vis_network_tmpl.qmd",
    cond = config$cond[[row]]
  ) |>
    knitr::knit(text = _, quiet = TRUE) |>
    cat()
  cat("\n\n")
}
```

```{r}
#| label: fig-brainnet-pred
#| eval: false
#| fig-width: 16
#| fig-height: 8
#| fig-cap: >
#|   **The brain networks of the most predictable sample.** Here we can find the
#|   difference between postive correlation networks and negative correlation
#|   networks.

# network atlas
network_labs_shen_268 <- c(
  MFN = "Medial Frontal",
  FPN = "Frontoparietal",
  DMN = "Default Mode",
  SC = "Subcortical-Cerebellum",
  MON = "Motor",
  VisI = "Visual I",
  VisII = "Visual II",
  VA = "Visual Association"
)
cols <- setNames(
  ggthemes::colorblind_pal()(length(network_labs_shen_268)),
  network_labs_shen_268
)
vis_mask <- function(mask, thresh_prop = 0.995) {
  restore_mat <- function(vec) {
    size <- (sqrt((8 * length(vec)) + 1) + 1) / 2
    mat <- matrix(0, nrow = size, ncol = size)
    mat[upper.tri(mat)] <- vec
    mat + t(mat)
  }
  shen_268_with_labs <- shen_268 |>
    mutate(network = factor(network, labels = network_labs_shen_268))
  brainconn(
    atlas = shen_268_with_labs,
    node.size = 1,
    conmat = restore_mat(mask) > thresh_prop,
    view = "left", edge.alpha = 0.2
  ) +
    scale_color_manual(values = cols, name = "Network")
}
data_masks <- preds_sampled |>
  filter(num_vars %in% c(4, 8, 12, 16), edge_type != "all") |>
  slice_max(cor, n = 1, by = c(num_vars, edge_type)) |>
  nest(.by = c(num_vars, id_pairs)) |>
  mutate(
    data = pmap(
      list(num_vars, id_pairs, data),
      \(num_vars, id_pairs, data, ...) {
        targets::tar_read_raw(
          str_c("brain_mask", num_vars, id_pairs, sep = "_")
        ) |>
          pivot_longer(
            any_of(edge_types),
            names_to = "edge_type",
            values_to = "mask"
          ) |>
          semi_join(data)
      }
    )
  ) |>
  unnest(data)
data_plots <- bind_rows(
  sampled = data_masks,
  "All Tasks" = targets::tar_read(mask_g_full, store = "_store_g_stability"),
  "RAPM" = targets::tar_read(mask_rapm, store = "_store_g_stability"),
  .id = "sample_type"
) |>
  arrange(edge_type, num_vars) |>
  mutate(
    id_task = if_else(is.na(num_vars), sample_type, sprintf("%d tasks", num_vars)),
    edge_type = case_match(
      edge_type,
      "neg" ~ "Anti-Corr",
      "pos" ~ "Pos-Corr"
    ),
    labels = str_glue("{id_task}, {edge_type}"),
    plots = map(mask, vis_mask)
  )
ggpubr::ggarrange(
  plotlist = data_plots$plots,
  nrow = 2, ncol = 6,
  labels = data_plots$labels,
  common.legend = TRUE,
  legend.grob = ggpubr::get_legend(data_plots$plots[[10]], position = "top")
)
```

# References
